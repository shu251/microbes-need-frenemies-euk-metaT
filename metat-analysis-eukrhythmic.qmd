---
title: "Frenemies-metaT-analysis"
format: html
editor: visual
---

*last updated Nov 2023*

# Introduction

Code for running metatranscriptome analysis with [eukrhythmic](https://eukrhythmic.readthedocs.io/en/latest/index.html). Data originates from several vent sites for project 'Microbes need frenmies'.

## Set up environment

```{r}
#| message: false
library(tidyverse)
```

## Create eukrhythmic sample list

Import .csv files for all samples names.

```{r}
#| echo: false
sample_list <- read.csv("input-docs/frenemies-sample-list.csv")
fastq_list <- read.csv("input-docs/frenemies-fastq-list.csv", header = FALSE)
```

Fastq files were run on both lanes 1 and 2. So will treat as replicates for now. Separate fastq_list file so we can left join the sample_list information.

For assembly groupings, we want diversity represented, but too much diversity may cause chimeric contigs. And if we put in too many reads, this can be a bottleneck for assembly (computationally).

Here, we decided to separate by vent field, sample type (vent vs. non-vent), and if there were many vents (like in the MCR sites), each vent was split into it's own assembly. Based on the 18S analysis, we know that vents even meters apart from one another can have very distinct and diverse communities. For the MCR work, some of the vent (in situ) samples were paired with shipboard grazing assays. These are assembled with the vent samples (as the original fluid was the same) and represent time final for the grazing experiments.

```{r}
# head(fastq_list)
# Create sample list for eukrhythmic input
sample_list_wassemblygroup <- fastq_list %>% 
  mutate(FastqFile = str_remove_all(V1, "_R1_001.fastq.gz"),
         SampleName = str_remove_all(FastqFile, "_S\\d+_L00\\d+")) %>% 
  left_join(sample_list %>% select(SampleName = SITE_NUM_FIELDYR_VENT_EXP_SAMPLEID, SAMPLEID, everything())) %>% 
  mutate(VENT = case_when(
    VENT == "Mustard Stand" ~ "MustardStand",
    TRUE ~ VENT
  )) %>% 
  mutate(TYPE = case_when( #Option to use casewhen for setting assembly grouping
  grepl("Plume", VENT) ~ "nonvent",
  grepl("plume", VENT) ~ "nonvent",
  grepl("Plus30m", VENT) ~ "nonvent",
  grepl("BSW", VENT) ~ "nonvent",
  grepl("Background", VENT) ~ "nonvent",
  grepl("Transit", VENT) ~ "nonvent",
  TRUE ~ "vent"
    )) %>%
  mutate(FIELD = case_when(
    FIELDYR == "VonDamm2020" ~ "VONDAMM",
    FIELDYR == "Piccard2020" ~ "PICCARD",
    TRUE ~ SITE
  )) %>% 
  mutate(AXIAL_CORR = case_when(
    grepl("IntlDistrict", VENT) ~ "IntlDistrict",
    grepl("ASHES", VENT) ~ "ASHES",
    grepl("Transit", VENT) ~ "Background",
    TRUE ~ VENT
  )) %>% 
  mutate(AssemblyGroup = case_when(
    SITE == "MCR" ~ paste(FIELD, VENT, TYPE, sep = "_"),
    SITE == "GR" ~ paste(FIELD, FIELDYR, TYPE, sep = "_"),
    SITE == "AXIAL" ~ paste(FIELD, AXIAL_CORR, TYPE, sep = "_")
  )) %>% 
  # unite("AssemblyGroup", c(FIELD, EXP, TYPE), remove = FALSE) %>% 
  mutate(SampleID = SampleName) %>% 
  select(SampleName, SampleID, AssemblyGroup, FastqFile, NUMBER = LAB_NUM, FIELD, SITE, FIELDYR, VENT, EXP, TYPE, SAMPLE_NAME, ORIGIN, SAMPLEID)
#SITE_NUM_FIELDYR_VENT_EXP_SAMPLEID
table(sample_list_wassemblygroup$AssemblyGroup)
# View(sample_list_wassemblygroup)
```

```{r}
# write_delim(sample_list_wassemblygroup %>% select(SampleName, SampleID, AssemblyGroup, FastqFile), file = "eukrhythmic-run/frenemies-metat-samplelist.txt", delim = "\t")
```

# Output from eukrhythmic

-   Salmon count files, `quant.sf`.
-   TaxonomicAndFunctionalAnnotations.csv

## Process with tximport

First run `scripts/create-samplelist.R`. This will output a sample list ready to be run with the tximport step.

Then execute `scripts/run_tximport_frenemies.R`. This will import all salmon count files and process transcript length to get transcript-level estimates as counts.

Output from above is an RData object that includes the txi object. This txi object can be subset for downstream analysis.

# Get dataframes for analysis

Import libraries and RData object

```{r}
library(DESeq2)
library(tidyverse)
library(tximport)
library(data.table)
# Test comment line!
load("/scratch/group/hu-lab/frenemies/euk-metaT-eukrhythmic-output/tximport-nov-2023.RData", verbose = TRUE)
```

## Subset by sample

Import sample list

```{r}
head(sample_merged)
```

```{r}
all <- sample_merged %>%
  select(sample = SampleName_rep)

mcr <- sample_merged %>% 
  filter(SITE == "MCR") %>% 
  select(sample = SampleName_rep)

axial <- sample_merged %>% 
  filter(SITE == "AXIAL") %>% 
  select(sample = SampleName_rep)
```

## Subset by taxa or gene ID

Temporary test

```{r}
# taxfxn <- read.table("/scratch/group/hu-lab/frenemies/euk-metaT-eukrhythmic-output/TaxonomicAndFunctionalAnnotations.csv", header = TRUE, sep = "\t")
taxfxn <- read.table("/scratch/group/hu-lab/frenemies/euk-metaT-eukrhythmic-output/TaxonomicAndFunctionalAnnotations.csv", header = TRUE, nrows = 250, sep = "\t")
```

```{r}
tx2gene_in <- taxfxn %>% 
  dplyr::mutate(SEQ_ID = stringr::str_remove(SequenceID, ".p[:digit:]$"))
```

Subset for eukaryotes

```{r}
euks_only <- as.character(tx2gene_in %>% 
  filter(grepl("Eukaryota", full_classification)) %>% 
  select(SEQ_ID) %>% 
    .[["SEQ_ID"]])
```

Subset for eukaryotes only and transcript must have annotation

```{r}
euks_annot_only <- as.character(
  filter(tx2gene_in, grepl("Eukaryota", full_classification) & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])
```

```{r}
save(all, mcr, axial, euks_only, euks_annot_only, file = "input-docs/objs-txi-subset.RData")
```

# Subset txi object

Function to subset txi object:

```{r}
# Subset txi directly
subsetTxi <- function(txi, samples, include_genes=rownames(txi$counts))
  {
  genes <- rownames(txi$counts)[rownames(txi$counts) %in% include_genes]
  txi$abundance <- txi$abundance[genes, samples$sample]
  txi$counts <- txi$counts[genes, samples$sample]
  txi$length <- txi$length[genes, samples$sample]
  return(txi)
  }

# Example usage 
# tmp <- sample(taxfxn$SequenceID,10,replace = FALSE)
# pola <- data.frame(sample = c("PortofLA_1", "PortofLA_2"))
# txi_pola <- subsetTxi(txi, pola, tmp)
```

To execute the above code for this project, see `scripts/subset-txi.R`.

Explanation of outputs:

# Analyze samples *in situ*

```{r}
load(file = "/scratch/group/hu-lab/frenemies/euk-metaT-eukrhythmic-output/txi-allsamples.RData", verbose = TRUE)
```

```         
txi_euk_annot <- subsetTxi(txi, all_no_tf, euks_annot_only)
txi_euk_only <- subsetTxi(txi, all_no_tf, euks_only)
```

## Extract count tables for analyses

```{r}
txi <- txi_euk_annot

library(tximport)

counts_scaled <- makeCountsFromAbundance(
  as.matrix(txi$counts),
  as.matrix(txi$abundance),
  as.matrix(txi$length),
  countsFromAbundance = "scaledTPM"
  # countsFromAbundance = "lengthScaledTPM"
)
# ?makeCountsFromAbundance()
counts_df <- as.data.frame(counts_scaled)
# colnames(counts_df)
```

Rename so replicates have the same name for counts

```{r}
names_orig <- colnames(counts_df)
names_new <- sub("_[^_]+$", "", names_orig)
colnames(counts_df) <- names_new
```

Mean across columns that have the same name - which are replicates.

```{r}
mean_counts_df <- counts_df %>%
  cbind(as.list(.) %>%
    Filter(is.numeric, .) %>%
    split(names(.)) %>%
    lapply(as.data.frame) %>%
    lapply(rowMeans) %>%
    setNames(paste0("mean.", names(.)))) %>% 
  select(starts_with("mean"))
```

Export for downstream analysis

```{r}
glimpse(mean_counts_df)
```

```{r}
save(mean_counts_df, file = "/scratch/group/hu-lab/frenemies/euk-metaT-eukrhythmic-output/all_samples_vent_metaT.RData")
```

```{r}
# head(taxfxn)
```

# Log FC for whole dataset

Extract centered data

```{r}
#| warning: false
#| message: false

# if (!require("BiocManager", quietly = TRUE))
    # install.packages("BiocManager")
# BiocManager::install("DESeq2")
library(DESeq2)
```

Get logFC for Vent versus non-vent and for plume versus background. `scripts/subset-txi.R` `scripts/subset-txi_Plume-v-BSW.R`

```{r}
# output is a DESeqtransform object
# ?vst()
vsd_all <- vst(ds_tpm_samplename)

# make a transformed count matrix
# vsd_blind <- vst(ds_tpm_samplename, blind = FALSE)
```

```{r}
head(assay(vsd_all), 4)
```

```{r}
df_ctr_norm <- as.data.frame(assay(vsd_all))
```

# Info

```{r}
sessionInfo()
```
